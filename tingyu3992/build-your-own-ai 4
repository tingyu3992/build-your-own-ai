import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# è¼‰å…¥è³‡æ–™
def load_data():
    embeddings = np.load('movie_embeddings.npy')
    titles = pd.read_csv('movie_titles.csv')['title'].tolist()
    return embeddings, titles

# å–å¾—è¼¸å…¥æ–‡å­—çš„åµŒå…¥
def get_text_embedding(text, model):
    return model.encode([text])[0]

# æ¨è–¦é‚è¼¯
def recommend_top_k(query_vector, embeddings, titles, k=5):
    sims = cosine_similarity([query_vector], embeddings)[0]
    top_k = np.argsort(sims)[::-1][:k]
    return [(titles[i], round(sims[i], 4)) for i in top_k]

# ä¸»æµç¨‹
def main():
    print("ğŸ¬ æ­¡è¿ä½¿ç”¨é›»å½±æ¨è–¦ç³»çµ±")
    embeddings, titles = load_data()
    model = SentenceTransformer('all-MiniLM-L6-v2')

    while True:
        user_input = input("\nè«‹è¼¸å…¥ä½ å–œæ­¡çš„é›»å½±æè¿°ï¼ˆæˆ–è¼¸å…¥ 'exit' é›¢é–‹ï¼‰ï¼š\n> ")
        if user_input.lower() == 'exit':
            break

        query_vector = get_text_embedding(user_input, model)
        results = recommend_top_k(query_vector, embeddings, titles)

        print("\nğŸ¯ æ¨è–¦çµæœï¼š")
        for i, (title, score) in enumerate(results, 1):
            print(f"{i}. {title} (ç›¸ä¼¼åº¦: {score})")

if __name__ == "__main__":
    main()
